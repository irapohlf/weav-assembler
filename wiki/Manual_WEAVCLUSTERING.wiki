#summary Everything for WEAV-CLUSTERING
#labels Featured
<wiki:toc max_depth="3" />

= Introduction =

WEAV-CLUSTERING tries to divide a big read set into smaller read set with keeping following features as possible as we can.
  * A clustered read set has not so many genes together. We hope a clustered read set has only one gene.
  * All the isoform of a gene would be in a clustered read set if exist.

||*Definition* Cluster: we will call *a clustered read set* as *a cluster*.||

= Compile =

Download WEAV-CLUSTERING tar ball and extract it.
{{{
> ls
common.h  config.h   copy.c  debug_message/  edge_table.h  extract.c    makefile    read_set.h  uniform.c  utils.c
config.c  config.in  data/   edge_table.c    euler.c       gpl-3.0.txt  read_set.c  tags        uniform.h  utils.h
}}}

Make it.
{{{
> make
g++ -ggdb -Wall -O2   -c -o euler.o euler.c
g++ -ggdb -Wall -O2   -c -o config.o config.c
g++ -ggdb -Wall -O2   -c -o read_set.o read_set.c
g++ -ggdb -Wall -O2   -c -o edge_table.o edge_table.c
g++ -ggdb -Wall -O2   -c -o utils.o utils.c
g++ -ggdb -Wall -O2   -c -o uniform.o uniform.c
g++ -o weav_clustering euler.o config.o read_set.o edge_table.o utils.o uniform.o -lm 
g++ -ggdb -Wall -O2   -c -o extract.o extract.c
g++ -o extract extract.o -lm 
ctags *.[ch]
> ls
common.h  config.in  data/           edge_table.h  euler.o    extract.o    read_set.c  tags       uniform.o  utils.o
config.c  config.o   debug_message/  edge_table.o  extract*   gpl-3.0.txt  read_set.h  uniform.c  utils.c    weav_clustering*
config.h  copy.c     edge_table.c    euler.c       extract.c  makefile     read_set.o  uniform.h  utils.h
}}}

You can find two binary files: EXTRACT and WEAV_CLUSTERING.

= Algorithm =

Although we want to keep the above features during clustering, fortunately, this clustering step does not have to be perfect, because the assembly algorithm of WEAV can assemble multiple genes simultaneously.
Thus we propose a naive clustering algorithm as follows.
  # We construct a de Bruijn graph with K-tuples using the whole read set. In this graph, the edges are K-tuples, the nodes are (K-1)-tuples, and the weight of an edge is the number of the K-tuple in the read set.
  # We remove edges with very low weight (i.e., <= 1) to eliminate random edges caused by sequencing errors, and we also remove edges with very high weight (i.e., >= 300) to eliminate edges caused by repetitive sequences. 
  # After edge removal, the graph is fragmented into many disjoint connected components, or subgraphs, which can be identified using the DFS (depth-first-search) algorithm. 
  # For each subgraph, we extract reads from the K-tuple edges and group them into a cluster.

= Run =

How to run the WEAV-CLUSTERING is closely related to the *Algorithm* discussed above. You can compare the following steps with above *Algorithm*.

== Construct K-mer Graph ==
You need `CONSTRUCT_KMER_TABLE` is on. In the contig.in you've gotten from tar ball, `CONSTRUCT_KMER_TABLE` would be commented out.
{{{
FILE_NAME=./data/test.reads
#REFINED_READS
#CONSTRUCT_KMER_TABLE
K=40
DEBUG_FILE=./debug_message/test
DEBUG=9
EXIT
}}}
There are two ways to make `CONSTRUCT_KMER_TABLE` on; using command-line argument or change config.in file. *We recommend to use command-line argument.*
{{{
> ./weav_clustering CONSTRUCT_KMER_TABLE
> ls
common.h   data/           euler.c      makefile    uniform.h
config.c   debug_message/  euler.o      read_set.c  uniform.o
config.h   edgeinfo        extract*     read_set.h  utils.c
config.in  edge_table.c    extract.c    read_set.o  utils.h
config.o   edge_table.h    extract.o    tags        utils.o
copy.c     edge_table.o    gpl-3.0.txt  uniform.c   weav_clustering*
}}}

As you can see, edgeinfo was generated from `./weav_clustering CONSTRUCT_KMER_TABLE`.

== Remove Heavy Edges ==

Weight one edges were removed already from *Construct K-mer Graph*, so we only need to care heavy edges here. This process is not automatic because the definition of *_heavy_* depends on many factors. So, users should define what is heavy. You can check the weight of edges from *edgeinfo* file.
As you can see from below, the file shows all the K-mers (here we used 40-mer) and their weight (it was sorted by the weight from light to heavy). You may check two things.
  * How heavy the edges are.
  * Which edge have heavy weight. For example, if there are many simple edges (AGAG...AGAG, AAAAAA....AAATT, and so on), it is better pre-process the read set. Surely, you can remove heavy edges by following way, but we recommend to pre-process because we think simple edges are not necessarily heavy. And, there can be other characteristics you may find from the edgeinfo.
{{{
> head edgeinfo
2,AAAAAAAAAGACAAGGAGAAAAAAGAGATCAAAAAGGAGA
2,AAAAAAAAATCTACAGAACATATGATCCTTCAAGTCAAAA
2,AAAAAAAAATGGAAGGATCTCAAGCTGATGAAAAAACTGG
2,AAAAAAAAATTCTCCGCCCCTTTCCTCGATCTCGCTCCCC
2,AAAAAAAAGACAAGGAGAAAAAAGAGATCAAAAAGGAGAG
2,AAAAAAAATAAACCCTCGTTCCACAGAAGCTGCCATCAAG
2,AAAAAAAATCTACAGAACATATGATCCTTCAAGTCAAAAA
2,AAAAAAAATGGAAGGATCTCAAGCTGATGAAAAAACTGGA
2,AAAAAAAATTCTCCGCCCCTTTCCTCGATCTCGCTCCCCC
2,AAAAAAACAAAAACAGAATTTGAGAACCTTGGACCACTCC
}}}

Anyway, decide how you would define *_heavy_*. If you decide to remove all the edges having weight 300 or higher. Do the following.
{{{
> ./extract 300
> ls
common.h   debug_message/  euler.o      read_set.h  utils.h
config.c   edgefp          extract*     read_set.o  utils.o
config.h   edgeinfo        extract.c    tags        weav_clustering*
config.in  edge_table.c    extract.o    uniform.c
config.o   edge_table.h    gpl-3.0.txt  uniform.h
copy.c     edge_table.o    makefile     uniform.o
data/      euler.c         read_set.c   utils.c
}}}

Now you can find *_edgefp_*. Actually edgefp is the graph using the edges after removing heavy edges. Note that edgeinfo still has all the edges. So, if you want to change the definition of heavy, you don't need to construct K-mer graph again. Just do EXTRACT with a new upper limit value.

== Cluster the Graph and the Read Set ==

Now you have the graph *_edgefp_*, and you will cluster the graph and the read set.
{{{
> ./weav_clustering
}}}

As you can see, we deleted the argument `CONSTRUCT_KMER_TABLE`. Just by not using the argument, we can make it off because our contig.in file has it with being commented out.

Then, in the directory where the read set was, you can find clustered read sets.
{{{
> ls data/
0/  1000/  500/  bridge  drop  test.reads  test.reads_refined
> ls data/0 | more
cluster_0
cluster_10
cluster_100
cluster_101
cluster_102
cluster_104
cluster_105
......
}}}

You can find two files _bridge_ and _drop_ and three directories `0/`, `500/` and `1000/`. We use one directory having 500 clusters because some OS does not allow to have too many files in a directory. So, we group clusters into subdirectories having at most 500 clusters. And, two files gives you the information following.
  * *bridge:* If two ends of a read fall into different subgraph, it cannot be joined to any of two subgraphs (in other words, clusters). Then, we collect them as a `bridge read`. You may use this read set if you want to have longer contigs.
  * *drop:* If two end-K-mers of a read, which are edges, are not part of any sub-graphs, the read cannot be added to any clustered read set. So, these reads may be useless.

= Config File =

WEAV-CLUSTERING also can use both `config.in` and command line argument like WEAV, and it shares general features with WEAV (please check [http://code.google.com/p/weav-assembler/wiki/Manual WEAV Manual]).


== Summary ==
||Field Name||Default Value||Type||Description||
||FILE_NAME||NO DEFAULT||String||Read set file path.||
||CONSTRUCT_KMER_TABLE||NO DEFAULT||NO VALUE||Yes/No for constructing a graph||
||K||25||Integer||K-mer length in _bp_.||
||DEBUG_FILE||NO DEFAULT||String||Debug message file path.||
||EXIT||NO DEFAULT||NO VALUE||Exit signal||


== Detailed Information ==
===_FILE_NAME_===
You may specify the read set in FASTA format. *Currently we only allow FASTA format, and reads should not have any invalid bases. WEAV only allows A,G,C and T (NOTE we don't allow a,g,c and t). We will update this feature as soon as possible.*
 After you specify the input read set by this field, following file name will be automatically generated: 
  * '_FILE_NAME_`_`refined' for `refined read set`.
Example:
{{{
3,AAAAATAGGTCATCAAAAGGAAAAAAAATAACTTTGATTAACTAGTGTTAAACAAAAAATAGGTTTACTAAATATGTTAATCTATTCTTTTAACATAAGC
1,AAAACAGTTCCCTAAGTTCAACTTTGTGGGGAAACTTTTGGGTCCACGTGGCAATTCTCTGAAGCGTTTACAAGAAGAAACCTTGACAAAAATGTCAATC
3,AAAACAGTTCCCTAAGTTCAACTTTGTGGGGAAACTTTTGGGTCCACGTGGCAATTCTCTGAAGCGTTTACAAGAAGAAACCTTGACAAAAATGTCCATC
...
}}}
This means the first read has 3 copies in the read set, the second has 1 copy, and so on.
These three files you can find in the directory where the read set is. *But there are several volatile files which would not be if WEAV is terminated normally, but would be if WEAV is terminated abnormally.* The volatile files are as follows.
===_CONSTRUCT_KMER_TABLE_===
If this field name is commented out, it means *_do not construct K-mer table, but clustering the graph and read set_*. If this field name is in the contig.in, it means *_construct K-mer table_*.
===_K_===
K-mer length which is a sequence length of an edge.
===_DEBUG_FILE_===
Not many information would be printed in terminal, and detailed information would be saved in this file.
===_EXIT_===
WEAV-CLUSTERING stops to read parameters after _EXIT_.